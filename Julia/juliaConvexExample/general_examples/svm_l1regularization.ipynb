{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SVM with L^1 regularization"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Generate data for SVM classifier with L1 regularization.\n",
    "using Random\n",
    "Random.seed!(3);\n",
    "n = 20;\n",
    "m = 1000;\n",
    "TEST = m;\n",
    "DENSITY = 0.2;\n",
    "beta_true = randn(n,1);\n",
    "idxs = randperm(n)[1:round(Int, (1-DENSITY)*n)];\n",
    "beta_true[idxs] .= 0\n",
    "offset = 0;\n",
    "sigma = 45;\n",
    "X = 5 * randn(m, n);\n",
    "Y = sign.(X * beta_true .+ offset .+ sigma * randn(m,1));\n",
    "X_test = 5 * randn(TEST, n);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Form SVM with L1 regularization problem.\n",
    "using Convex, SCS, ECOS\n",
    "\n",
    "beta = Variable(n);\n",
    "v = Variable();\n",
    "loss = sum(pos(1 - Y .* (X*beta - v)));\n",
    "reg = norm(beta, 1);\n",
    "\n",
    "# Compute a trade-off curve and record train and test error.\n",
    "TRIALS = 100\n",
    "train_error = zeros(TRIALS);\n",
    "test_error = zeros(TRIALS);\n",
    "lambda_vals = exp10.(range(-2, stop=0, length=TRIALS);)\n",
    "beta_vals = zeros(length(beta), TRIALS);\n",
    "for i = 1:TRIALS\n",
    "    lambda = lambda_vals[i];\n",
    "    problem = minimize(loss/m + lambda*reg);\n",
    "    solve!(problem, () -> ECOS.Optimizer(verbose=0));\n",
    "    # solve!(problem, SCS.Optimizer(verbose=0,linear_solver=SCS.Direct, eps=1e-3))\n",
    "    train_error[i] = sum(float(sign.(X*beta_true .+ offset) .!= sign.(evaluate(X*beta - v))))/m;\n",
    "    test_error[i] = sum(float(sign.(X_test*beta_true .+ offset) .!= sign.(evaluate(X_test*beta - v))))/TEST;\n",
    "    beta_vals[:, i] =  evaluate(beta);\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the train and test error over the trade-off curve."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Plots\n",
    "plot(lambda_vals, train_error, label=\"Train error\");\n",
    "plot!(lambda_vals, test_error, label=\"Test error\");\n",
    "plot!(xscale=:log, yscale=:log, ylabel=\"errors\", xlabel=\"lambda\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the regularization path for beta."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot()\n",
    "for i = 1:n\n",
    "    plot!(lambda_vals, vec(beta_vals[i,:]), label=\"beta$i\")\n",
    "end\n",
    "plot!(xscale=:log, ylabel=\"betas\", xlabel=\"lambda\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  },
  "kernelspec": {
   "name": "julia-1.0",
   "display_name": "Julia 1.0.5",
   "language": "julia"
  }
 },
 "nbformat": 4
}
